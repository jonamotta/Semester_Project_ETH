{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to JupyROOT 6.16/00\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jonamotta/anaconda3/envs/python_root/lib/python2.7/site-packages/root_numpy/__init__.py:46: RuntimeWarning: numpy 1.16.3 is currently installed but you installed root_numpy against numpy 1.9.3. Please consider reinstalling root_numpy for this numpy version.\n",
      "  RuntimeWarning)\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import ROOT\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import root_pandas\n",
    "import seaborn as sb\n",
    "import matplotlib.pyplot as plt\n",
    "import uproot\n",
    "import time\n",
    "\n",
    "from itertools import product\n",
    "\n",
    "#from root_numpy import root2array\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, auc\n",
    "from sklearn.preprocessing import QuantileTransformer\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "########################################\n",
    "### READ TREES AND CREATE DATAFRAMES ###\n",
    "########################################\n",
    "\n",
    "\n",
    "# fix random seed for reproducibility\n",
    "np.random.seed(1986)\n",
    "\n",
    "#create DataFrames with the values coming from the trees\n",
    "file_tau = uproot.open('../bc_jpsi_tau_nu_gen_v2.root')\n",
    "tree_tau = file_tau['tree;1']\n",
    "tau  = tree_tau.pandas.df(tree_tau.keys())\n",
    "\n",
    "file_mu = uproot.open('../bc_jpsi_mu_nu_gen_v2.root')\n",
    "tree_mu = file_mu['tree;2']\n",
    "mu  = tree_mu.pandas.df(tree_mu.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running time to add the new vars to the df = 15161.4\n"
     ]
    }
   ],
   "source": [
    "############################################\n",
    "### ADD NECESSARY FEATURES TO DATAFRAMES ###\n",
    "############################################\n",
    "\n",
    "\n",
    "# some of these features are taken from the LHCb paper and have to be computed and added to the dataframes\n",
    "features = [\n",
    "    'm2_miss', #missing mass square (p_B - p_mu1 - p_mu2 - p_mu)^2\n",
    "    'muE_Brf', #mu energy in the Bc rest frame\n",
    "    'q2', #squared 4momentum transfer to lepton sys (p_B - p_mu1 - p_mu2)^2\n",
    "    'pT_miss', #missing transverse momentum (p_B - p_mu1 - p_mu2 - p_mu).Pt\n",
    "    'mu_pt'     ,\n",
    "    'mu_eta'    ,\n",
    "    'mu_phi'    ,\n",
    "    #'mu_charge' ,\n",
    "    'mu1_pt'    ,\n",
    "    'mu1_eta'   ,\n",
    "    'mu1_phi'   ,\n",
    "    #'mu1_charge',\n",
    "    'mu2_pt'    ,\n",
    "    'mu2_eta'   ,\n",
    "    'mu2_phi'   ,\n",
    "    #'mu2_charge',\n",
    "]\n",
    "\n",
    "mu_events = pd.DataFrame(columns=features)\n",
    "tau_events = pd.DataFrame(columns=features)\n",
    "\n",
    "#add the column target to both dataframes\n",
    "mu_events['target'] = 0\n",
    "tau_events['target'] = 1\n",
    "\n",
    "bc_vect = ROOT.TLorentzVector()\n",
    "jpsi_vect = ROOT.TLorentzVector()\n",
    "mu_vect = ROOT.TLorentzVector()\n",
    "mu1_vect = ROOT.TLorentzVector()\n",
    "mu2_vect = ROOT.TLorentzVector()\n",
    "reco_vect = ROOT.TLorentzVector()\n",
    "PV = ROOT.TVector3()\n",
    "SV = ROOT.TVector3()\n",
    "mu_mass = 0.10565837 #GeV/c^2\n",
    "jpsi_mass = 3.096900 #GeV/c^2\n",
    "bc_mass = 6.2756 #GeV/c^2\n",
    "c = 2.99e8 #m/s\n",
    "\n",
    "# in the following, when creating the TLorentzVector of mu, mu1, mu2 we try to account for the reconstruction error\n",
    "# made by the tracker and the muon system in the value of pT\n",
    "# we include a gaussian smearing -> we draw a value of pT from a gaussian centered at the value of the MC pT of the\n",
    "#                                   muon and with sigma 7% of the value of the MC pT (CMS performance)\n",
    "start = time.time()\n",
    "i = 0\n",
    "k = 0\n",
    "while i < mu['run'].count():\n",
    "    # we take only the events for which the muons atre all inside the acceptance of the CMS detector\n",
    "    if abs(mu.at[i,'mu_eta']) < 2.4 and abs(mu.at[i,'mu1_eta']) < 2.4 and abs(mu.at[i,'mu2_eta']) < 2.4 and mu.at[i,'mu_pt'] > 1.0 and mu.at[i,'mu1_pt'] > 1.0 and mu.at[i,'mu2_pt'] > 1.0:\n",
    "        # the muon ID efficiency is 0.96 therefore we first of all draw from a uniform distribution between 0 and 1\n",
    "        # and we check that the value is <0.96**3 (because we have 3 muons in the final state)\n",
    "        # if this is not the case we 'throw away' the event\n",
    "        if np.random.uniform(0,1) < 0.96**3:\n",
    "            # the following ifs look for events in the barrel, else they are in the endcap\n",
    "            if abs(mu.at[i,'mu_eta']) < 1.2 and mu.at[i,'mu_pt'] > 3:\n",
    "                mu_vect.SetPtEtaPhiM(max(np.random.normal(mu.at[i,'mu_pt'], mu.at[i,'mu_pt']*1/100),0),mu.at[i,'mu_eta'],mu.at[i,'mu_phi'],mu_mass)\n",
    "            else:\n",
    "                mu_vect.SetPtEtaPhiM(max(np.random.normal(mu.at[i,'mu_pt'], mu.at[i,'mu_pt']*3/100),0),mu.at[i,'mu_eta'],mu.at[i,'mu_phi'],mu_mass)\n",
    "            if abs(mu.at[i,'mu1_eta']) < 1.2 and mu.at[i,'mu1_pt'] > 3:\n",
    "                mu1_vect.SetPtEtaPhiM(max(np.random.normal(mu.at[i,'mu1_pt'], mu.at[i,'mu1_pt']*1/100),0),mu.at[i,'mu1_eta'],mu.at[i,'mu1_phi'],mu_mass)\n",
    "            else:\n",
    "                mu1_vect.SetPtEtaPhiM(max(np.random.normal(mu.at[i,'mu1_pt'], mu.at[i,'mu1_pt']*3/100),0),mu.at[i,'mu1_eta'],mu.at[i,'mu1_phi'],mu_mass)\n",
    "            if abs(mu.at[i,'mu2_eta']) < 1.2 and mu.at[i,'mu2_pt'] > 3:\n",
    "                mu2_vect.SetPtEtaPhiM(max(np.random.normal(mu.at[i,'mu2_pt'], mu.at[i,'mu2_pt']*1/100),0),mu.at[i,'mu2_eta'],mu.at[i,'mu2_phi'],mu_mass)\n",
    "            else:\n",
    "                mu2_vect.SetPtEtaPhiM(max(np.random.normal(mu.at[i,'mu2_pt'], mu.at[i,'mu2_pt']*3/100),0),mu.at[i,'mu2_eta'],mu.at[i,'mu2_phi'],mu_mass)\n",
    "                \n",
    "            # set the PV and SV and calculate primary-secondary vertex distance\n",
    "            # include smearing of PV reconstruction with a gaussian smearing taken from a CMS paper\n",
    "            # include smearing of SV reconstruction with a gaussian smearing with sigma double of the PV one\n",
    "            PV.SetXYZ(np.random.normal(mu.at[i,'pv_x']*1e-2, 20*1e-6),np.random.normal(mu.at[i,'pv_y']*1e-2, 20*1e-6),np.random.normal(mu.at[i,'pv_z']*1e-2, 30*1e-6))\n",
    "            SV.SetXYZ(np.random.normal(mu.at[i,'sv_x']*1e-2, 40*1e-6),np.random.normal(mu.at[i,'sv_y']*1e-2, 40*1e-6),np.random.normal(mu.at[i,'sv_z']*1e-2, 60*1e-6))\n",
    "            dist_PSV = np.sqrt((PV.X()-SV.X())**2+(PV.Y()-SV.Y())**2+(PV.Z()-SV.Z())**2)\n",
    "            \n",
    "            reco_vect = mu_vect + mu1_vect + mu2_vect\n",
    "    \n",
    "            # using the reconstruction of pT  \n",
    "            bc_pTreco = bc_mass * reco_vect.Pt() / reco_vect.Mag() \n",
    "            bc_vect.SetPtEtaPhiM(bc_pTreco,mu.at[i,'bc_eta'],mu.at[i,'bc_phi'],bc_mass)\n",
    "            \n",
    "            # we look for the best roconstruction of the jpsi \n",
    "            muons = [mu_vect,mu1_vect,mu2_vect]\n",
    "            muons_charge = [mu.at[i,'mu_charge'],mu.at[i,'mu1_charge'],mu.at[i,'mu2_charge']]\n",
    "            pair_vect = ROOT.TLorentzVector()\n",
    "            if muons_charge[0] != muons_charge[1]:\n",
    "                pair1_vect = muons[0] + muons[1]\n",
    "                unpaired_mu1 = muons[2]\n",
    "                pair2_vect = muons[1] + muons[2]\n",
    "                unpaired_mu2 = muons[0]\n",
    "            else:\n",
    "                pair1_vect = muons[0] + muons[2]\n",
    "                unpaired_mu1 = muons[1]\n",
    "                pair2_vect = muons[1] + muons[2]\n",
    "                unpaired_mu2 = muons[0]\n",
    "\n",
    "            if (abs(pair1_vect.Mag() - jpsi_mass)) < abs((pair2_vect.Mag() - jpsi_mass)):\n",
    "                mu_events.at[k,'muon_pair'] = 0 # indicating the best reco is mu+mu1/2\n",
    "                q2_vect = bc_vect - pair1_vect\n",
    "                unpaired_mu = unpaired_mu1\n",
    "            else:\n",
    "                mu_events.at[k,'muon_pair'] = 1 # indicating the best reco is mu1+mu2\n",
    "                q2_vect = bc_vect - pair2_vect\n",
    "                unpaired_mu = unpaired_mu2\n",
    "            \n",
    "            m2_vect = bc_vect - reco_vect\n",
    "\n",
    "            mu_events.at[k,'m2_miss'] = m2_vect.Mag2()\n",
    "            mu_events.at[k,'pT_miss'] = m2_vect.Pt()\n",
    "            mu_events.at[k,'q2'] = q2_vect.Mag2()\n",
    "            mu_events.at[k,'muE_Brf'] = unpaired_mu.E() * np.cosh(unpaired_mu.Rapidity() - bc_vect.Rapidity())\n",
    "            \n",
    "            # decay length and time\n",
    "            mu_events.at[k,'bc_DL'] = dist_PSV\n",
    "            mu_events.at[k,'bc_CT'] = dist_PSV / (bc_vect.Gamma()*bc_vect.Beta())\n",
    "            \n",
    "            # add the missing info to the new df\n",
    "            mu_events.at[k,'mu1_pt'] = mu.at[i,'mu1_pt']\n",
    "            mu_events.at[k,'mu1_eta'] = mu.at[i,'mu1_eta']\n",
    "            mu_events.at[k,'mu1_phi'] = mu.at[i,'mu1_phi']\n",
    "            mu_events.at[k,'mu2_pt'] = mu.at[i,'mu2_pt']\n",
    "            mu_events.at[k,'mu2_eta'] = mu.at[i,'mu2_eta']\n",
    "            mu_events.at[k,'mu2_phi'] = mu.at[i,'mu2_phi']\n",
    "            mu_events.at[k,'mu_pt'] = mu.at[i,'mu_pt']\n",
    "            mu_events.at[k,'mu_eta'] = mu.at[i,'mu_eta']\n",
    "            mu_events.at[k,'mu_phi'] = mu.at[i,'mu_phi']\n",
    "                \n",
    "            k += 1\n",
    "                \n",
    "    i +=1\n",
    "\n",
    "# ------ end one loop, start the other ------ # \n",
    "    \n",
    "i = 0\n",
    "k = 0\n",
    "while i < tau['run'].count():\n",
    "    # we take only the events for which the muons are all inside the acceptance of the CMS detector\n",
    "    if abs(tau.at[i,'mu_eta']) < 2.4 and abs(tau.at[i,'mu1_eta']) < 2.4 and abs(tau.at[i,'mu2_eta']) < 2.4 and tau.at[i,'mu_pt'] > 1.0 and tau.at[i,'mu1_pt'] > 1.0 and tau.at[i,'mu2_pt'] > 1.0:\n",
    "        # the muon ID efficiency is 0.96 therefore we first of all draw from a uniform distribution between 0 and 1\n",
    "        # and we check that the value is <0.96**3 (because we have 3 muons in the final state)\n",
    "        # if this is not the case we 'throw away' the event\n",
    "        if np.random.uniform(0,1) < 0.96**3:\n",
    "            # the following ifs look for events in the barrel, else they are in the endcap\n",
    "            if abs(tau.at[i,'mu_eta']) < 1.2 and tau.at[i,'mu_pt'] > 3:\n",
    "                mu_vect.SetPtEtaPhiM(max(np.random.normal(tau.at[i,'mu_pt'], tau.at[i,'mu_pt']*1/100),0),tau.at[i,'mu_eta'],tau.at[i,'mu_phi'],mu_mass)\n",
    "            else:\n",
    "                mu_vect.SetPtEtaPhiM(max(np.random.normal(tau.at[i,'mu_pt'], tau.at[i,'mu_pt']*3/100),0),tau.at[i,'mu_eta'],tau.at[i,'mu_phi'],mu_mass)\n",
    "            if abs(tau.at[i,'mu1_eta']) < 1.2 and tau.at[i,'mu1_pt'] > 3:\n",
    "                mu1_vect.SetPtEtaPhiM(max(np.random.normal(tau.at[i,'mu1_pt'], tau.at[i,'mu1_pt']*1/100),0),tau.at[i,'mu1_eta'],tau.at[i,'mu1_phi'],mu_mass)\n",
    "            else:\n",
    "                mu1_vect.SetPtEtaPhiM(max(np.random.normal(tau.at[i,'mu1_pt'], tau.at[i,'mu1_pt']*3/100),0),tau.at[i,'mu1_eta'],tau.at[i,'mu1_phi'],mu_mass)\n",
    "            if abs(tau.at[i,'mu2_eta']) < 1.2 and tau.at[i,'mu2_pt'] > 3:\n",
    "                mu2_vect.SetPtEtaPhiM(max(np.random.normal(tau.at[i,'mu2_pt'], tau.at[i,'mu2_pt']*1/100),0),tau.at[i,'mu2_eta'],tau.at[i,'mu2_phi'],mu_mass)\n",
    "            else:\n",
    "                mu2_vect.SetPtEtaPhiM(max(np.random.normal(tau.at[i,'mu2_pt'], tau.at[i,'mu2_pt']*3/100),0),tau.at[i,'mu2_eta'],tau.at[i,'mu2_phi'],mu_mass)\n",
    "                \n",
    "            # set the PV and SV and calculate primary-secondary vertex distance\n",
    "            # include smearing of PV reconstruction with a gaussian smearing taken from a CMS paper\n",
    "            # include smearing of SV reconstruction with a gaussian smearing with sigma double of the PV one\n",
    "            PV.SetXYZ(np.random.normal(tau.at[i,'pv_x']*1e-2, 20*1e-6),np.random.normal(tau.at[i,'pv_y']*1e-2, 20*1e-6),np.random.normal(tau.at[i,'pv_z']*1e-2, 30*1e-6))\n",
    "            SV.SetXYZ(np.random.normal(tau.at[i,'sv_x']*1e-2, 40*1e-6),np.random.normal(tau.at[i,'sv_y']*1e-2, 40*1e-6),np.random.normal(tau.at[i,'sv_z']*1e-2, 60*1e-6))\n",
    "            dist_PSV = np.sqrt((PV.X()-SV.X())**2+(PV.Y()-SV.Y())**2+(PV.Z()-SV.Z())**2)\n",
    "\n",
    "            reco_vect = mu_vect + mu1_vect + mu2_vect\n",
    "\n",
    "            # using the reconstruction of pT instead of pZ\n",
    "            bc_pTreco = (bc_mass / reco_vect.Mag()) * reco_vect.Pt()\n",
    "            bc_vect.SetPtEtaPhiM(bc_pTreco,tau.at[i,'bc_eta'],tau.at[i,'bc_phi'],bc_mass)\n",
    "            \n",
    "            # we look for the best roconstruction of the jpsi \n",
    "            muons = [mu_vect,mu1_vect,mu2_vect]\n",
    "            muons_charge = [tau.at[i,'mu_charge'],tau.at[i,'mu1_charge'],tau.at[i,'mu2_charge']]\n",
    "            if muons_charge[0] != muons_charge[1]:\n",
    "                pair1_vect = muons[0] + muons[1]\n",
    "                unpaired_mu1 = muons[2]\n",
    "                pair2_vect = muons[1] + muons[2]\n",
    "                unpaired_mu2 = muons[0]\n",
    "            else:\n",
    "                pair1_vect = muons[0] + muons[2]\n",
    "                unpaired_mu1 = muons[1]\n",
    "                pair2_vect = muons[1] + muons[2]\n",
    "                unpaired_mu2 = muons[0]\n",
    "\n",
    "            if (abs(pair1_vect.Mag() - jpsi_mass)) < abs((pair2_vect.Mag() - jpsi_mass)):\n",
    "                tau_events.at[k,'muon_pair'] = 0 # indicating the best reco is mu+mu1/2\n",
    "                q2_vect = bc_vect - pair1_vect\n",
    "                unpaired_mu = unpaired_mu1\n",
    "            else:\n",
    "                tau_events.at[k,'muon_pair'] = 1 # indicating the best reco is mu1+mu2\n",
    "                q2_vect = bc_vect - pair2_vect\n",
    "                unpaired_mu = unpaired_mu2\n",
    "            \n",
    "            m2_vect = bc_vect - reco_vect\n",
    "\n",
    "            tau_events.at[k,'m2_miss'] = m2_vect.Mag2()\n",
    "            tau_events.at[k,'pT_miss'] = m2_vect.Pt()\n",
    "            tau_events.at[k,'q2'] = q2_vect.Mag2()\n",
    "            tau_events.at[k,'muE_Brf'] = unpaired_mu.E() * np.cosh(unpaired_mu.Rapidity() - bc_vect.Rapidity())\n",
    "\n",
    "            # decay length and decay time(c*tau)\n",
    "            tau_events.at[k,'bc_DL'] = dist_PSV\n",
    "            tau_events.at[k,'bc_CT'] = dist_PSV / (bc_vect.Gamma()*bc_vect.Beta())\n",
    "            \n",
    "            # add the missing info to the new df\n",
    "            tau_events.at[k,'mu1_pt'] = tau.at[i,'mu1_pt']\n",
    "            tau_events.at[k,'mu1_eta'] = tau.at[i,'mu1_eta']\n",
    "            tau_events.at[k,'mu1_phi'] = tau.at[i,'mu1_phi']\n",
    "            tau_events.at[k,'mu2_pt'] = tau.at[i,'mu2_pt']\n",
    "            tau_events.at[k,'mu2_eta'] = tau.at[i,'mu2_eta']\n",
    "            tau_events.at[k,'mu2_phi'] = tau.at[i,'mu2_phi']\n",
    "            tau_events.at[k,'mu_pt'] = tau.at[i,'mu_pt']\n",
    "            tau_events.at[k,'mu_eta'] = tau.at[i,'mu_eta']\n",
    "            tau_events.at[k,'mu_phi'] = tau.at[i,'mu_phi']\n",
    "\n",
    "            k += 1\n",
    "                \n",
    "    i += 1\n",
    "    \n",
    "end = time.time()\n",
    "print 'Running time to add the new vars to the df = %.1f'%(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#######################################################\n",
    "### ADD TARGET COLUMNS AND SAVE CSV FILES OF EVENTS ###\n",
    "#######################################################\n",
    "\n",
    "mu['target'] = 0\n",
    "mu_events['target'] = 0\n",
    "tau['target'] = 1\n",
    "tau_events['target'] = 1\n",
    "\n",
    "mu_events.to_csv('mu_events.csv')\n",
    "tau_events.to_csv('tau_events.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
